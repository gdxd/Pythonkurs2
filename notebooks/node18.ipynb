{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Node 18: Synchronisation](http://www-static.etp.physik.uni-muenchen.de/kurs/Computing/python2/node18.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigation:\n",
    "\n",
    "**Next:** [Python-Threads und GIL](node19.ipynb) **Up:** [Python-Threads und GIL](node19.ipynb) **Previous:** [Python-Threads und GIL](node19.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synchronization\n",
    "In the previous examples, the threads run independently of each other. It gets more complicated when they access shared data areas, especially when one thread is writing and another is reading the shared data. The following – somewhat constructed – example illustrates the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "ITERS = 100000\n",
    "x = [0]\n",
    "\n",
    "def worker():\n",
    "    for _ in range(ITERS):\n",
    "        x[0] += int(1)  # this line creates a race condition\n",
    "        # because it takes a value, increments and then writes\n",
    "        # some inrcements can be done together, and lost\n",
    "\n",
    "def main():\n",
    "    x[0] = 0  # you may use `global x` instead of this list trick too\n",
    "    t1 = threading.Thread(target=worker)\n",
    "    t2 = threading.Thread(target=worker)\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "for i in range(5):\n",
    "    main()\n",
    "    print(f'iteration {i}. expected x = {ITERS*2}, got {x[0]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you get out**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both threads access the same <font color=#008000> *Counter object*</font>, i.e. they use the same <font color=#ff0000> **member variable**</font> **self.num**.\n",
    " \n",
    "\n",
    "Depending on the randomness, we get the expected result (200000) or another number between 100000 and 200000. The program is non-deterministic, although no random numbers are used... This phenomenon is called [\"race condition\"](https://dribbble.com/shots/3157258-Race-Condition-Programming-Joke) because the dependence of the result on the call order, which in turn depends on the distribution of CPU time among each thread.\n",
    " \n",
    "\n",
    "In the example, we only get the race condition when using this extra function `int(1)` to get the value of 1. \n",
    "Otherwise **GIL** (next nb) would prevent it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locking\n",
    "The <font color=#ff0000> **Locking**</font> mechanism offers a real remedy in Python (among others):\n",
    "* <font color=#0000e6> ``lock = threading.Lock()``</font> object is created\n",
    "* Calling <font color=#0000e6> ``lock.acquire()``</font> before executing critical area\n",
    "* First thread that calls <font color=#0000e6> ``lock.acquire()``</font> keeps running\n",
    "* Next thread that <font color=#0000e6> ``lock.acquire()``</font> has to wait\n",
    "* until first thread <font color=#0000e6> calls ``lock.release()``</font>\n",
    "* etc.\n",
    "\n",
    "This ensures that the <font color=#008000> *inc()*</font> method is only executed by <font color=#ff0000> **one**</font> thread at a time, all others are as long as blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "ITERS = 100000\n",
    "x = [0]\n",
    "\n",
    "def worker(lock):\n",
    "    for _ in range(ITERS):\n",
    "        lock.acquire() \n",
    "        x[0] += int(1)  \n",
    "        lock.release()     \n",
    "\n",
    "def main():\n",
    "# lock\n",
    "    lock    = threading.Lock() \n",
    "\n",
    "# create two threads \n",
    "    x[0] = 0  # you may use `global x` instead of this list trick too\n",
    "    t1 = threading.Thread(target=worker, args = (lock,))\n",
    "    t2 = threading.Thread(target=worker, args = (lock,))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "for i in range(5):\n",
    "    main()\n",
    "    print(f'iteration {i}. expected x = {ITERS*2}, got {x[0]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the result is correct, but the `locking` leads to speed losses.\n",
    "\n",
    "**Task**: Think about how you rate the relative execution speed of the wrong and right variant, but also compared to a single-threaded variant. Measure the speed of the different options (hint: `%%time`) and compare them. Explain the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the two threads together will even be significantly slower than a single one. Programming with parallel threads obviously needs great care and planning to really bring about a speed gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
